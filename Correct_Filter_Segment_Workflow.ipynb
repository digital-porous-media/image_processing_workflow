{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f8fea4",
   "metadata": {},
   "source": [
    "# Corrections, Filtering and Segmentation Notebook\n",
    "\n",
    "## This notebook is tested with the Offshore Langseth Dataset\n",
    "\n",
    "## The workflow is as follows:\n",
    "* **Beam hardening correction on each sample in this set**\n",
    "    * Sample plots: \n",
    "        * Before (i) and after (ii) radial correction on one slice, and their radial profiles (iii). Radial profile of average slice through that particular section (before and after) (iv).\n",
    "* **Histogram equalization**\n",
    "    * Sample plots:\n",
    "        * Before (i) and after (ii) histogram equalization on one slice, and their histograms (iii). Histogram of an average slice through that particular section (before and after) (iv).\n",
    "\n",
    "\n",
    "* **Two different filters after previous steps:**\n",
    "    1. **Median filter**\n",
    "    * Sample plots:\n",
    "        * Before (i) and after (ii) median filter on one slice, and their radial profiles (iii). Histogram of an average slice through that particular section (before and after) (iv).\n",
    "    2. **Anisotropic diffusion filter**\n",
    "    * Sample plots:\n",
    "        * Before (i) and after (ii) anisotropic diffusion filter on one slice, and their radial profiles (iii). Histogram of an average slice through that particular section (before and after) (iv).\n",
    "\n",
    "* **Various Segmentation Methods**\n",
    "* **Shape analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('error', category=DeprecationWarning)\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "from IPython.display import HTML\n",
    "import concurrent, multiprocessing\n",
    "import re\n",
    "import Worflow_functions as SRAF\n",
    "import copy\n",
    "import pickle\n",
    "import cc3d\n",
    "import pyvista as pv \n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "\n",
    "def get_occuppied_mem():\n",
    "    mem = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "    print(f\"{mem:12.4f} MB\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687e713",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# sample_names = ['sample_1',\n",
    "#                 'sample_2',\n",
    "#                 'sample_3',\n",
    "#                 ...]\n",
    "\n",
    "sample_name='sample_1'\n",
    "\n",
    "\n",
    "# Uncomment to see the used memory\n",
    "# mem_before = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        #reads the folder names\n",
    "        info_list_for_dict = [executor.submit(SRAF.prepare_sample,sample_name) for sample_name in sample_names]\n",
    "        #reads the data\n",
    "        dict_data = [executor.submit(SRAF.create_dict,info.result()) for info in info_list_for_dict]\n",
    "\n",
    "# Uncomment to see the used memory\n",
    "    # for sample in concurrent.futures.as_completed(dict_data):\n",
    "    #     mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "    # print(f\"{mem_after - mem_before:12.4f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5379ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_data = list([data.result() for data in dict_data])\n",
    "# mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "# print(f\"{mem_after:12.4f} MB\")\n",
    "\n",
    "whole_data_dict = {}\n",
    "for i,dict_item in enumerate(dict_data):\n",
    "    item = dict_item     \n",
    "    key = sample_names[i].replace('-','_')\n",
    "    if key not in whole_data_dict:\n",
    "        whole_data_dict[key] = item\n",
    "\n",
    "# mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "# print(f\"{mem_after:12.4f} MB\")\n",
    "\n",
    "# Modifies the data by clipping the first and last 50 slices\n",
    "for sample in whole_data_dict:\n",
    "    SRAF.modify_dict(whole_data_dict[sample])\n",
    "        \n",
    "# mem_after = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n",
    "# print(f\"{mem_after:12.4f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fddb01",
   "metadata": {},
   "source": [
    "## Checking the sections to see if all of them are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344907b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in whole_data_dict:\n",
    "    print(data, ':', list(whole_data_dict[data].keys()))\n",
    "\n",
    "# Alternative:\n",
    "# for data in whole_data_dict:\n",
    "#     print(data, *list(whole_data_dict[data].keys()), sep = \"\\n  ├──\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf8ab4",
   "metadata": {},
   "source": [
    "## Checking the section dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions after cropping the first and last 50 slices\n",
    "counter=0\n",
    "for data in whole_data_dict:\n",
    "    for section in whole_data_dict[data].keys():\n",
    "        print(np.array(whole_data_dict[data][section]).shape)\n",
    "        counter+=1\n",
    "print(f'\\nTotal number of slices: {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc966d6",
   "metadata": {},
   "source": [
    "## Beam Hardening Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the packages, not necessary at this moment.\n",
    "# import importlib\n",
    "# importlib.reload(SRAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corrected_sample={}\n",
    "for sample in whole_data_dict:\n",
    "    corrected_sample[sample] = SRAF.radially_correct_section(whole_data_dict[sample])\n",
    "# get_occuppied_mem()\n",
    "\n",
    "# Alternative\n",
    "\n",
    "# get_occuppied_mem()\n",
    "# if __name__=='__main__':\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor2:\n",
    "#         #applies radial correction\n",
    "#         corrected_section = [executor2.submit(SRAF.radially_correct_section, whole_data_dict[sample_name.replace('-','_')], 45) for section in whole_data_dict[sample_name.replace('-','_')]]       \n",
    "# #     for sample in concurrent.futures.as_completed(dict_data):\n",
    "        \n",
    "# get_occuppied_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcc7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRAF.visualize_radial_correction(sample_name=sample_name, \n",
    "                                 original_sample=whole_data_dict[sample_name.replace('-','_')], \n",
    "                                 corrected_sample=corrected_sample[sample_name.replace('-','_')],\n",
    "                                 profile_angle_degrees=45,\n",
    "                                 slice_to_plot=100,\n",
    "                                 save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c307ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_occuppied_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f5718",
   "metadata": {},
   "source": [
    "## Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for sample in corrected_sample:\n",
    "    for section in corrected_sample[sample]:\n",
    "        for i in range(0,len(corrected_sample[sample][section])):\n",
    "            corrected_sample[sample][section][i,:,:] = skimage.exposure.equalize_adapthist(corrected_sample[sample][section][i,:,:].astype(int))\n",
    "        print(f'{sample}, {section} completed.')\n",
    "get_occuppied_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRAF.visualize_filter(sample_name=sample_name, \n",
    "                             original_sample=whole_data_dict[sample_name.replace('-','_')], \n",
    "                             corrected_sample=corrected_sample[sample_name.replace('-','_')],\n",
    "                             mask_radius=190,\n",
    "                             filter_name='Adapt. Hist. Eq.',\n",
    "                             slice_to_plot=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f70a53",
   "metadata": {},
   "source": [
    "## Median Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf93067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__=='__main__':\n",
    "    sample = sample_name.replace('-','_')\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor3:\n",
    "        #reads the folder names\n",
    "        med_sections_Futures = [executor3.submit(skimage.filters.median,corrected_sample[sample][section],skimage.morphology.cube(3)) for section in corrected_sample[sample]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71082164",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_filtered_sample=copy.deepcopy(corrected_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,section in enumerate(median_filtered_sample[sample_name.replace('-','_')]):\n",
    "    median_filtered_sample[sample_name.replace('-','_')][section] = med_sections_Futures[i].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRAF.visualize_filter(sample_name=sample_name, \n",
    "                             original_sample=corrected_sample[sample_name.replace('-','_')], \n",
    "                             corrected_sample=median_filtered_sample[sample_name.replace('-','_')],\n",
    "                             mask_radius=190,\n",
    "                             filter_name='Median Filter',\n",
    "                             slice_to_plot=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029e859",
   "metadata": {},
   "source": [
    "## Anisotropic diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if __name__=='__main__':\n",
    "    sample = sample_name.replace('-','_')\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor3:\n",
    "        #reads the folder names\n",
    "        anid_sections_Futures = [executor3.submit(SRAF.anisotropic_diffusion,corrected_sample[sample][section],niter=5) for section in corrected_sample[sample]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "anid_filtered_sample=copy.deepcopy(corrected_sample)\n",
    "for i,section in enumerate(anid_filtered_sample[sample_name.replace('-','_')]):\n",
    "    anid_filtered_sample[sample_name.replace('-','_')][section] = anid_sections_Futures[i].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SRAF.visualize_filter(sample_name=sample_name, \n",
    "                      original_sample=corrected_sample[sample_name.replace('-','_')], \n",
    "                      corrected_sample=anid_filtered_sample[sample_name.replace('-','_')],\n",
    "                      mask_radius=190,\n",
    "                      filter_name='Ani. Diff. Filter 10 iter',\n",
    "                      slice_to_plot=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6380a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save dictionary to .pkl file\n",
    "with open(f'{sample_name}_filtered_sample_ready_for_segmentation.pkl', 'wb') as fp:\n",
    "    pickle.dump(anid_filtered_sample, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e931837",
   "metadata": {},
   "source": [
    "## Median vs Anisotropic Diffusion Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd485d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SRAF.compare_filters(sample_name, \n",
    "                     data1=median_filtered_sample[sample_name.replace('-','_')], \n",
    "                     data1_name='Median',\n",
    "                     data2=anid_filtered_sample[sample_name.replace('-','_')], \n",
    "                     data2_name='Ani. Diff.',\n",
    "                     mask_radius=190,\n",
    "                     slice_to_plot=100,\n",
    "                     save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f635db",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_occuppied_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54997e8",
   "metadata": {},
   "source": [
    "## Thresholding and Segmenting\n",
    "\n",
    "Anisotropic diffusion is used. It can be modified to be median as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa187b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the filtered data if importing locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3457c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anid_filtered_sample=copy.deepcopy(corrected_sample)\n",
    "for i,section in enumerate(anid_filtered_sample[sample_name.replace('-','_')]):\n",
    "    anid_filtered_sample[sample_name.replace('-','_')][section] = anid_sections_Futures[i].result()\n",
    "\n",
    "# Alternative\n",
    "# sample = sample_name.replace('-','_')\n",
    "\n",
    "# for section in anid_filtered_sample[sample]:\n",
    "#     anid_filtered_sample[sample][section] = SRAF.mask_section(anid_filtered_sample[sample][section],\n",
    "#                                                                            mask_radius=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "otsu=copy.deepcopy(anid_filtered_sample)\n",
    "\n",
    "sample = sample_name.replace('-','_')\n",
    "\n",
    "# Assing number of classes\n",
    "classes = 4\n",
    "\n",
    "for section in anid_filtered_sample[sample]:\n",
    "    otsu[sample][section] = skimage.filters.threshold_multiotsu(anid_filtered_sample[sample][section],classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea19921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See thresholds\n",
    "otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "thresholded_sample = copy.deepcopy(anid_filtered_sample)\n",
    "\n",
    "sample = sample_name.replace('-','_')\n",
    "\n",
    "for section in anid_filtered_sample[sample]:\n",
    "    thresholded_sample[sample][section] = np.digitize(anid_filtered_sample[sample][section],bins=otsu[sample][section])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If manual adjustments are needed, similar scheme can be used:\n",
    "# for section in thresholded_sample[sample]:\n",
    "#     thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==2]=5\n",
    "#     thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==3]=5\n",
    "#     thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==4]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,15),sharex=True, sharey=True)\n",
    "ax[0].imshow(anid_filtered_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "im = ax[1].imshow(thresholded_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample][section] = skimage.morphology.erosion(thresholded_sample[sample][section],\n",
    "                                                                     footprint=skimage.morphology.cube(2))\n",
    "    \n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,15),sharex=True, sharey=True)\n",
    "ax[0].imshow(anid_filtered_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "im = ax[1].imshow(thresholded_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642d06f",
   "metadata": {},
   "source": [
    "## Preparing sample for measuring properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = sample_name.replace('-','_')\n",
    "\n",
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample][section] = SRAF.mask_section(thresholded_sample[sample][section],\n",
    "                                                            mask_radius=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e46140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresholded_sample[sample]['Section 1'][100,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9b9b3",
   "metadata": {},
   "source": [
    "Inversing the colors and assigning 0 to the masked regions since we don't want their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==0]=4\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==1]=5\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==2]=6\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==3]=7\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==1.17122018]=0\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==4]=1\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==5]=2\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==6]=3\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==7]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6409006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==2]=1\n",
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==3]=2\n",
    "for section in thresholded_sample[sample]:\n",
    "    thresholded_sample[sample_name.replace('-','_')][section][thresholded_sample[sample_name.replace('-','_')][section]==4]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresholded_sample[sample]['Section 1'][100,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035f2d4",
   "metadata": {},
   "source": [
    "## Saving and checking the saved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save dictionary to .pkl file\n",
    "with open(f'{sample_name}_otsu_segmented.pkl', 'wb') as fp:\n",
    "    pickle.dump(thresholded_sample, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1762d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{sample_name}_otsu_segmented.pkl', 'rb') as fp:\n",
    "    loaded_sample = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30af28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,15),sharex=True, sharey=True)\n",
    "ax[0].imshow(anid_filtered_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "im = ax[1].imshow(loaded_sample[sample_name.replace('-','_')]['Section 1'][100,:,:],interpolation=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfd0d4",
   "metadata": {},
   "source": [
    "# Different segmentation methods\n",
    "## i. Segmenting with region merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439de333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def weight_boundary(graph, src, dst, n):\n",
    "    \"\"\"\n",
    "    Handle merging of nodes of a region boundary region adjacency graph.\n",
    "\n",
    "    This function computes the `\"weight\"` and the count `\"count\"`\n",
    "    attributes of the edge between `n` and the node formed after\n",
    "    merging `src` and `dst`.\n",
    "\n",
    "skimage.\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : RAG\n",
    "        The graph under consideration.\n",
    "    src, dst : int\n",
    "        The vertices in `graph` to be merged.\n",
    "    n : int\n",
    "        A neighbor of `src` or `dst` or both.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        A dictionary with the \"weight\" and \"count\" attributes to be\n",
    "        assigned for the merged node.\n",
    "\n",
    "    \"\"\"\n",
    "    default = {'weight': 0.0, 'count': 0}\n",
    "\n",
    "    count_src = graph[src].get(n, default)['count']\n",
    "    count_dst = graph[dst].get(n, default)['count']\n",
    "\n",
    "    weight_src = graph[src].get(n, default)['weight']\n",
    "    weight_dst = graph[dst].get(n, default)['weight']\n",
    "\n",
    "    count = count_src + count_dst\n",
    "    return {\n",
    "        'count': count,\n",
    "        'weight': (count_src * weight_src + count_dst * weight_dst)/count\n",
    "    }\n",
    "\n",
    "\n",
    "def merge_boundary(graph, src, dst):\n",
    "    \"\"\"Call back called before merging 2 nodes.\n",
    "\n",
    "    In this case we don't need to do any computation here.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "sample = sample_name.replace('-','_')\n",
    "\n",
    "\n",
    "masked_sample = copy.deepcopy(anid_filtered_sample)\n",
    "for section in anid_filtered_sample[sample]:\n",
    "    masked_sample[sample][section] = SRAF.mask_section(anid_filtered_sample[sample][section],\n",
    "                                                                           mask_radius=180) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sample:\n",
    "\n",
    "# for section in anid_filtered_sample[sample]:\n",
    "#     otsu[sample][section] = skimage.filters.threshold_multiotsu(anid_filtered_sample[sample][section],classes=4)\n",
    "\n",
    "gimg = masked_sample[sample]['Section 1'][100,:,:]\n",
    "img_color=skimage.color.gray2rgb(gimg)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12,12),sharex=True, sharey=True)\n",
    "ax[0,0].imshow(gimg,interpolation=None)\n",
    "ax[0,0].set_title('Filtered Sample')\n",
    "\n",
    "labels = skimage.segmentation.slic(img_color, compactness=30, n_segments=2000, start_label=1)\n",
    "edges = skimage.filters.sobel(gimg)\n",
    "edges_rgb = skimage.color.gray2rgb(edges)\n",
    "\n",
    "g = skimage.graph.rag_boundary(labels, edges)\n",
    "lc = skimage.graph.show_rag(\n",
    "    labels, g, edges_rgb, img_cmap=None, edge_cmap='viridis', edge_width=1.2,ax=ax[0,1])\n",
    "\n",
    "ax[0,1].set_title('Region Adjacency Graph')\n",
    "\n",
    "labels2 = skimage.graph.merge_hierarchical(labels, g, thresh=0.06, rag_copy=False,\n",
    "                                   in_place_merge=True,\n",
    "                                   merge_func=merge_boundary,\n",
    "                                   weight_func=weight_boundary)\n",
    "\n",
    "skimage.graph.show_rag(labels, g, img_color, ax = ax[1,0])\n",
    "ax[1,0].set_title('RAG after hierarchical merging')\n",
    "\n",
    "# out = skimage.color.label2rgb(labels2, img_color, kind='avg', bg_label=0)\n",
    "im = ax[1,1].imshow(labels2, interpolation=None, vmin=np.min(np.unique(labels2)), vmax = np.max(np.unique(labels2)))\n",
    "ax[1,1].set_title('Final segmentation')\n",
    "# plt.tight_layout()\n",
    "plt.colorbar(lc, ax=ax[0,1])\n",
    "plt.colorbar(im, ax=ax[1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab278da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21672bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mod = copy.deepcopy(labels2)\n",
    "cond1 = out_mod>=18\n",
    "cond2 = (out_mod<18)&(out_mod>12)\n",
    "cond3 = out_mod<=12\n",
    "out_mod = np.select(condlist=[cond1,cond2,cond3],choicelist=[2,1,0])\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "ax.imshow(out_mod, interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a650f4a",
   "metadata": {},
   "source": [
    "#### We aren't happy with the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb1e94",
   "metadata": {},
   "source": [
    "## ii. Random Walker Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sample = copy.deepcopy(anid_filtered_sample)\n",
    "for section in anid_filtered_sample[sample]:\n",
    "    masked_sample[sample][section] = SRAF.mask_section(anid_filtered_sample[sample][section],\n",
    "                                                                           mask_radius=180) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e635cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = masked_sample[sample]['Section 1']\n",
    "np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = masked_sample[sample]['Section 1']\n",
    "\n",
    "markers = np.zeros(data.shape, dtype=np.uint)\n",
    "\n",
    "markers[(data > 0)&(data < 0.2)] = 1\n",
    "markers[(data > 0.5)&(data < 0.7)] = 2\n",
    "markers[(data > 0.9)&(data < 1)] = 3\n",
    "markers[data == 1.17122018] = 0\n",
    "\n",
    "# Run random walker algorithm\n",
    "labels = skimage.segmentation.random_walker(data, markers, beta=10, mode='bf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfbd46",
   "metadata": {},
   "source": [
    "### -- Computationally too expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012c71c",
   "metadata": {},
   "source": [
    "## iii. Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = pv.examples.load_random_hills()\n",
    "arrows = mesh.glyph(scale='Normals', orient='Normals', tolerance = 0.05)\n",
    "pv.set_jupyter_backend('trame')\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(arrows, color='black')\n",
    "p.add_mesh(mesh, scalars='Elevation', cmap = 'terrain', smooth_shading=True)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "sample_name = sample_name.replace('-','_')\n",
    "with open(f'{sample_name}_filtered_sample_ready_for_segmentation.pkl', 'rb') as fp:\n",
    "    loaded_sample = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(loaded_sample[sample_name.replace('-','_')]['Section 1'][100:200,100:200,100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = sample_name.replace('-','_')\n",
    "\n",
    "for section in loaded_sample[sample]:\n",
    "    loaded_sample[sample][section] = SRAF.mask_section(loaded_sample[sample][section],\n",
    "                                                                           mask_radius=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faea203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample images to try watershed\n",
    "image = loaded_sample[sample_name.replace('-','_')]['Section 1'][100,:,:]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,5),sharex=True, sharey=True)\n",
    "im = ax.imshow(image,interpolation=None)\n",
    "plt.tight_layout()\n",
    "plt.colorbar(mappable=im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=3,figsize=(18,15))\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4,figsize=(25,20))\n",
    "\n",
    "ax=axes.flatten()\n",
    "for axis in ax:\n",
    "    axis.axis('off')\n",
    "ax[0].imshow(image, interpolation=None)\n",
    "\n",
    "# 1. Gradients\n",
    "scharr = skimage.filters.scharr(image)\n",
    "ax[1].imshow(scharr, interpolation=None)\n",
    "\n",
    "# 2. Dilation (Opening-Closing)\n",
    "dilated = skimage.morphology.dilation(image, footprint=skimage.morphology.disk(3))\n",
    "ax[2].imshow(dilated, interpolation=None)\n",
    "\n",
    "# 2. Reconstructuon by dilation \n",
    "# https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.reconstruction\n",
    "# seed = np.copy(image)\n",
    "# seed[1:-1, 1:-1] = image.max()\n",
    "\n",
    "mask_radius = 160\n",
    "center = (image.shape[0]/2,image.shape[1]/2)\n",
    "x, y = np.meshgrid(np.arange(470), np.arange(470))\n",
    "\n",
    "# Calculating the distances from the center\n",
    "r = np.sqrt((center[0] - x)**2 + (center[1] - y)**2)\n",
    "\n",
    "# Apply np.select to get the diff values\n",
    "seed = np.where(r == mask_radius, image,image.max())\n",
    "\n",
    "\n",
    "rec = skimage.morphology.reconstruction(seed=seed, mask=image, method='erosion')\n",
    "ax[3].imshow(rec, interpolation=None)\n",
    "\n",
    "fgm = rec-image\n",
    "ax[4].imshow(fgm, interpolation=None)\n",
    "\n",
    "ax[5].imshow(image, cmap='gray', interpolation=None)\n",
    "ax[5].imshow(fgm, alpha = 0.8, interpolation=None)\n",
    "fgm_rescaled = skimage.exposure.rescale_intensity(fgm, in_range=(0,0.52774596),out_range=(0,1))\n",
    "otsu = skimage.filters.threshold_multiotsu(fgm_rescaled,classes=2)\n",
    "\n",
    "markers = np.digitize(image,bins=[0,0.5])\n",
    "distance = scipy.ndimage.distance_transform_edt(fgm)\n",
    "ax[6].imshow(distance, interpolation=None)\n",
    "\n",
    "ax[7].imshow(markers, interpolation=None)\n",
    "\n",
    "local_maxi = skimage.feature.peak_local_max(fgm, min_distance=5)\n",
    "\n",
    "peaks_mask = np.zeros_like(fgm, dtype=bool)\n",
    "peaks_mask[local_maxi] = True\n",
    "ax[8].imshow(peaks_mask, interpolation=None)\n",
    "\n",
    "labels = skimage.segmentation.watershed(-distance,markers = peaks_mask ,watershed_line=True)\n",
    "ax[9].imshow(labels, interpolation=None)\n",
    "\n",
    "# fgm_dilated = skimage.morphology.dilation(fgm, footprint=skimage.morphology.disk(3))\n",
    "# ax[6].imshow(image, cmap='gray')\n",
    "# ax[6].imshow(fgm_dilated, alpha = 0.8)\n",
    "\n",
    "\n",
    "\n",
    "#     markers = np.zeros(image.shape, dtype=np.uint)\n",
    "#     markers[(image > 0)&(image < thresholds_array[i][0])] = 1\n",
    "#     markers[(image > thresholds_array[i][0])&(image < thresholds_array[i][1])] = 2\n",
    "#     markers[(image > thresholds_array[i][1])&(image < thresholds_array[i][2])] = 3\n",
    "#     markers[(image > thresholds_array[i][2])] = 4\n",
    "\n",
    "#     regions = np.digitize(image, bins=thresholds_array[i])\n",
    "\n",
    "#     regions = regions + np.ones(regions.shape)\n",
    "# #     labels = skimage.segmentation.watershed(image, regions)\n",
    "\n",
    "#     sobel = skimage.filters.sobel(image)  \n",
    "#     img_sobel_digitized = 1- skimage.morphology.binary_dilation(np.digitize(sobel,[0.5]))\n",
    "\n",
    "#     np.place(regions,img_sobel_digitized == 0,0)\n",
    "    \n",
    "#     labels = skimage.segmentation.watershed(image, regions)\n",
    "#     footprint = skimage.morphology.square(3)\n",
    "#     labels = skimage.morphology.closing(labels, footprint)\n",
    "#     ax[i+3].imshow(labels, interpolation=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3175b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(markers)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15759fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_8 = image.astype(np.uint8)\n",
    "# otsu = skimage.filters.threshold_multiotsu(fgm_rescaled,classes=2)\n",
    "thresholded = np.digitize(image,bins=[0.5])\n",
    "thresholded = skimage.util.invert(thresholded)\n",
    "thresholded = skimage.exposure.rescale_intensity(thresholded,out_range=(0,255))\n",
    "plt.imshow(thresholded, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresholded,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "plt.imshow(opening, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(thresholded,kernel,iterations=1)\n",
    "plt.imshow(sure_bg, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Finding sure foreground area\n",
    "distance = scipy.ndimage.distance_transform_edt(sure_bg)\n",
    "# dist_transform = cv2.distanceTransform(thresholded,cv2.DIST_L2,3)\n",
    "plt.imshow(distance, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "otsu = skimage.filters.threshold_otsu(distance)\n",
    "sure_fg = np.digitize(distance,bins=[otsu])\n",
    "plt.imshow(sure_fg, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Finding unknown regions\n",
    "unknown = sure_bg - sure_fg\n",
    "\n",
    "plt.imshow(unknown, cmap='gray', interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Marker labelling\n",
    "# Connected Components determines the connectivity of blob-like regions in a binary image.\n",
    "sure_fg = sure_fg.astype(np.uint8)\n",
    "\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "plt.imshow(markers, interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# markers = cv2.watershed(col_img.astype(np.uint8),col_mark.astype(np.uint8))\n",
    "watershed = skimage.segmentation.watershed(image=image,\n",
    "                                         markers=markers,\n",
    "                                        watershed_line=True)\n",
    "plt.imshow(image, interpolation=None)\n",
    "plt.imshow(watershed, interpolation=None, alpha = 0.5)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image, interpolation=None)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(watershed==markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce32bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "470*470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb0ec74",
   "metadata": {},
   "source": [
    "## Measuring properties\n",
    "### A kernel restart is suggested for clearing the memory and only uploading the segmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ef217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cc3d\n",
    "# https://github.com/seung-lab/connected-components-3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = sample_name.replace('-','_')\n",
    "with open(f'{sample_name}_otsu_segmented.pkl', 'rb') as fp:\n",
    "    loaded_sample = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the Fracture Plane\n",
    "isolation=loaded_sample[sample_name.replace('-','_')]['Section 1']\n",
    "isolation = isolation * (isolation == 1)\n",
    "plt.imshow(isolation[100,:,:], interpolation=None)\n",
    "plt.colorbar()\n",
    "print(np.unique(isolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a labeling of the k largest objects in the image.\n",
    "# The output will be relabeled from 1 to N.\n",
    "\n",
    "labels_out, N = cc3d.largest_k(\n",
    "  isolation, k=15,  # or thresholded sample if the whole workflow is run\n",
    "  connectivity=26, delta=0,\n",
    "  return_N=True,\n",
    ")\n",
    "\n",
    "# labels_in *= (labels_out > 0) # to get original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the voxel counts per component\n",
    "index,counts = np.unique(labels_out,return_counts=True)\n",
    "combined = np.array([index,counts])\n",
    "combined = combined.T\n",
    "combined[combined[:,1].argsort()][::-1]\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the array for component properties \n",
    "no_of_props_to_collect = 3\n",
    "props_array = np.zeros((max(index),no_of_props_to_collect))\n",
    "  \n",
    "for segid in range(1, N+1):\n",
    "    extracted_image = labels_out * (labels_out == segid)\n",
    "    props = skimage.measure.regionprops(extracted_image)\n",
    "    props_array[segid-1,0]=props[0].area\n",
    "    props_array[segid-1,1]=props[0].axis_minor_length\n",
    "    props_array[segid-1,2]=props[0].feret_diameter_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cac131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for props\n",
    "df = pd.DataFrame(data=props_array)\n",
    "df.rename(columns={0:'Volume',1:'Axis_min',2:'Feret_max'}, inplace=True)\n",
    "df['Shape_factor'] = df['Axis_min']/df['Feret_max']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a45bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES NOT WORK YET, SO AN ALTERNATIVE VISUALIZATION IS PROVIDED IN THE NEXT CELL\n",
    "\n",
    "# #cmap based on shape factor\n",
    "# shape_colors=np.zeros((len(df['Shape_factor']),4))\n",
    "# for i in range(0,3):\n",
    "#     shape_colors[:,i] = df['Shape_factor'].values\n",
    "# shape_colors[:,0:4]=1\n",
    "# pv_lookuptable = pv.LookupTable(values=shape_colors,\n",
    "#                                 scalar_range=(0,1))\n",
    "# #lookup table does not work yet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccaa0e",
   "metadata": {},
   "source": [
    "### Shape colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condlist = np.arange(1,len(df)+1)\n",
    "condlist = [labels_out==condlist[i] for i in range(0,len(df))]\n",
    "choicelist = list(df['Shape_factor'])\n",
    "\n",
    "vol_shape_modified = np.select(condlist=condlist, choicelist=choicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Colored Components for plotting in spyder\n",
    "\n",
    "with open(f'{sample_name}_section_1_shapes_colored.pkl', 'wb') as fp:\n",
    "    pickle.dump(vol_shape_modified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af16b7",
   "metadata": {},
   "source": [
    "### Volume colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc90a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condlist = np.arange(1,len(df)+1)\n",
    "condlist = [labels_out==condlist[i] for i in range(0,len(df))]\n",
    "choicelist = list(df['Volume'])\n",
    "\n",
    "vol_vol_modified = np.select(condlist=condlist, choicelist=choicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a575cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Colored Components for plotting in spyder\n",
    "\n",
    "with open(f'{sample_name}_section_1_volumes_colored.pkl', 'wb') as fp:\n",
    "    pickle.dump(vol_vol_modified, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vol = np.sum(df['Volume'])\n",
    "normalized_vols = df['Volume']/total_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47011045",
   "metadata": {},
   "outputs": [],
   "source": [
    "condlist = np.arange(1,len(df)+1)\n",
    "condlist = [labels_out==condlist[i] for i in range(0,len(df))]\n",
    "choicelist = list(normalized_vols)\n",
    "\n",
    "vol_vol_modified_normalized = np.select(condlist=condlist, choicelist=choicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20125a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Colored Components for plotting in spyder\n",
    "\n",
    "with open(f'{sample_name}_section_1_volumes_colored.pkl', 'wb') as fp:\n",
    "    pickle.dump(vol_vol_modified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e3a36",
   "metadata": {},
   "source": [
    "## Histogram analysis for number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f739c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
